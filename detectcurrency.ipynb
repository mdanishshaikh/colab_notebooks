{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "detectcurrency.ipynb",
      "provenance": [],
      "mount_file_id": "1RNjmsOzWAasJgEp4p1-RDT7N7-7QdAGr",
      "authorship_tag": "ABX9TyOMQ9UR9tUkSfxiVZ9xxW2X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mdanishshaikh/colab_notebooks/blob/master/detectcurrency.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "BMIj0NY7QILs"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import math\n",
        "import numpy as np\n",
        "from pprint import pprint"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# read image as is\n",
        "def read_img(file_name):\n",
        "\timg = cv2.imread(file_name)\n",
        "\treturn img\n",
        "\n",
        "\n",
        "# resize image with fixed aspect ratio\n",
        "def resize_img(image, scale):\n",
        "\tres = cv2.resize(image, None, fx=scale, fy=scale, interpolation = cv2.INTER_AREA)\n",
        "\treturn res\n",
        "\n",
        "\n",
        "# convert image to grayscale\n",
        "def img_to_gray(image):\n",
        "\timg_gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
        "\treturn img_gray\n",
        "\n",
        "\n",
        "# gaussian blurred grayscale\n",
        "def img_to_gaussian_gray(image):\n",
        "\timg_gray = cv2.GaussianBlur(img_to_gray(image), (5, 5), 0)\n",
        "\treturn img_gray\n",
        "\n",
        "\n",
        "# convert image to negative\n",
        "def img_to_neg(image):\n",
        "\timg_neg = 255 - image\n",
        "\treturn img_neg\n",
        "\n",
        "\n",
        "# binarize (threshold)\n",
        "# retval not used currently\n",
        "def binary_thresh(image, threshold):\n",
        "\tretval, img_thresh = cv2.threshold(image, threshold, 255, cv2.THRESH_BINARY)\n",
        "\treturn img_thresh\n",
        "\n",
        "\n",
        "# NO IDEA HOW THIS WPRKS\n",
        "def adaptive_thresh(image):\n",
        "\timg_thresh = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 8)\n",
        "\t# cv2.adaptiveThreshold(src, maxValue, adaptiveMethod, thresholdType, blockSize, C[, dst]) â†’ dsta\n",
        "\treturn img_thresh\n",
        "\n",
        "\n",
        "# sobel edge operator\n",
        "def sobel_edge(image, align):\n",
        "\timg_horiz = cv2.Sobel(image, cv2.CV_8U, 0, 1)\n",
        "\timg_vert = cv2.Sobel(image, cv2.CV_8U, 1, 0)\n",
        "\tif align == 'h':\n",
        "\t\treturn img_horiz\n",
        "\telif align == 'v':\n",
        "\t\treturn img_vert\n",
        "\telse:\n",
        "\t\tprint('use h or v')\n",
        "\n",
        "\n",
        "# sobel edge x + y\n",
        "def sobel_edge2(image):\n",
        "\t# ksize = size of extended sobel kernel\n",
        "\tgrad_x = cv2.Sobel(image, cv2.CV_16S, 1, 0, ksize=3, borderType = cv2.BORDER_DEFAULT)\n",
        "\tgrad_y = cv2.Sobel(image, cv2.CV_16S, 0, 1, ksize=3, borderType = cv2.BORDER_DEFAULT)\n",
        "\n",
        "\tabs_grad_x = cv2.convertScaleAbs(grad_x)\n",
        "\tabs_grad_y = cv2.convertScaleAbs(grad_y)\n",
        "\n",
        "\tdst = cv2.addWeighted(abs_grad_x, 0.5, abs_grad_y, 0.5, 0)\n",
        "\treturn dst\n",
        "\n",
        "\n",
        "# canny edge operator\n",
        "def canny_edge(image, block_size, ksize):\n",
        "\t# block_size => Neighborhood size\n",
        "\t# ksize => Aperture parameter for the Sobel operator\n",
        "\t\n",
        "\t# 350, 350 => for smaller 500\n",
        "\t# 720, 350 => Devnagari 500, Reserve bank of India\n",
        "\t\n",
        "\timg = cv2.Canny(image, block_size, ksize)\n",
        "\t# dilate to fill up the numbers\n",
        "\t#img = cv2.dilate(img, None)\n",
        "\treturn img\n",
        "\n",
        "\n",
        "# laplacian edge\n",
        "def laplacian_edge(image):\n",
        "\t# good for text\n",
        "\timg = cv2.Laplacian(image, cv2.CV_8U)\n",
        "\treturn img\n",
        "\n",
        "\n",
        "# detect countours\n",
        "def find_contours(image):\n",
        "\t(_, contours, _) = cv2.findContours(image, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\tcontours = sorted(contours, key = cv2.contourArea, reverse = True)[:5]\n",
        "\treturn contours\n",
        "\n",
        "\n",
        "# median blur\n",
        "def median_blur(image):\n",
        "\tblurred_img = cv2.medianBlur(image, 3)\n",
        "\treturn blurred_img\n",
        "\n",
        "\n",
        "# dialte image to close lines\n",
        "def dilate_img(image):\n",
        "\timg = cv2.dilate(image, np.ones((5,5), np.uint8))\n",
        "\treturn img\n",
        "\n",
        "\n",
        "# erode image\n",
        "def close(image):\n",
        "\timg = cv2.Canny(image, 75, 300)\n",
        "\timg = cv2.dilate(img, None)\n",
        "\timg = cv2.erode(img, None)\n",
        "\treturn img\n",
        "\n",
        "\n",
        "def harris_edge(image):\n",
        "\timg_gray = np.float32(image)\n",
        "\n",
        "\tcorners = cv2.goodFeaturesToTrack(img_gray, 4, 0.03, 200, None, None, 2,useHarrisDetector=True, k=0.04)\n",
        "\tcorners = np.int0(corners)\n",
        "\n",
        "\tfor corner in corners:\n",
        "\t\tx, y = corner.ravel()\n",
        "\t\tcv2.circle(image, (x, y), 3, 255, -1)\n",
        "\treturn image\n",
        "\n",
        "\n",
        "# calculate histogram\n",
        "def histogram(image):\n",
        "\thist = cv2.calcHist([image], [0], None, [256], [0, 256])\n",
        "\t# cv2.calcHist(images, channels, mask, histSize, ranges[, hist[, accumulate]]) \n",
        "\n",
        "\n",
        "# fast fourier transform\n",
        "def fourier(image):\n",
        "\tf = np.fft.fft2(image)\n",
        "\tfshift = np.fft.fftshift(f)\n",
        "\tmagnitude_spectrum = 20 * np.log(np.abs(fshift))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# calculate scale and fit into display\n",
        "def display(window_name, image):\n",
        "\tscreen_res = 1440, 900\t# MacBook Air\n",
        "\t\n",
        "\tscale_width = screen_res[0] / image.shape[1]\n",
        "\tscale_height = screen_res[1] / image.shape[0]\n",
        "\tscale = min(scale_width, scale_height)\n",
        "\twindow_width = int(image.shape[1] * scale)\n",
        "\twindow_height = int(image.shape[0] * scale)\n",
        "\n",
        "\t# reescale the resolution of the window\n",
        "\tcv2.namedWindow(window_name, cv2.WINDOW_NORMAL)\n",
        "\tcv2.resizeWindow(window_name, window_width, window_height)\n",
        "\n",
        "\t# display image\n",
        "\tcv2.imshow(window_name, image)\n",
        "\n",
        "\t# wait for any key to quit the program\n",
        "\tcv2.waitKey(0)\n",
        "\tcv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "OtPZuqbhQWBj"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "max_val = 8\n",
        "max_pt = -1\n",
        "max_kp = 0"
      ],
      "metadata": {
        "id": "RJOehBOlTDzm"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "orb = cv2.ORB_create(nfeatures=2500)\n",
        "test_img = read_img('/content/drive/MyDrive/100train/INDIA100OLD_4.jpg')\n",
        "(kp1, des1) = orb.detectAndCompute(test_img, 1)\t\n",
        "training_set = ['/content/drive/MyDrive/100train/INDIA100OLD_1.jpg','/content/drive/MyDrive/100train/INDIA100OLD_2.jpg','/content/drive/MyDrive/100train/INDIA100OLD_3.jpg','/content/drive/MyDrive/100train/INDIA100OLD_4.jpg','/content/drive/MyDrive/100train/INDIA100OLD_5.jpg','/content/drive/MyDrive/100train/INDIA10NEW_160.jpg','/content/drive/MyDrive/100train/INDIA10NEW_159.jpg','/content/drive/MyDrive/100train/INDIA10NEW_153.jpg','/content/drive/MyDrive/100train/INDIA10NEW_154.jpg','/content/drive/MyDrive/100train/INDIA10NEW_156.jpg','/content/drive/MyDrive/100train/INDIA10NEW_146.jpg','/content/drive/MyDrive/100train/INDIA50NEW_1.jpg','/content/drive/MyDrive/100train/INDIA50NEW_2.jpg','/content/drive/MyDrive/100train/INDIA50NEW_3.jpg','/content/drive/MyDrive/100train/INDIA50NEW_4.jpg','/content/drive/MyDrive/100train/INDIA50NEW_5.jpg','/content/drive/MyDrive/100train/INDIA50NEW_6.jpg','/content/drive/MyDrive/100train/INDIA20_1.jpg','/content/drive/MyDrive/100train/INDIA20_2.jpg','/content/drive/MyDrive/100train/INDIA20_3.jpg','/content/drive/MyDrive/100train/INDIA20_4.jpg','/content/drive/MyDrive/100train/INDIA20_5.jpg','/content/drive/MyDrive/100train/INDIA20_7.jpg']"
      ],
      "metadata": {
        "id": "2f4-_QhJTfe7"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0, len(training_set)):\n",
        " train_img = cv2.imread(training_set[i])\n",
        " (kp2, des2) = orb.detectAndCompute(train_img, None)\n",
        " bf = cv2.BFMatcher()\n",
        " all_matches = bf.knnMatch(des1, des2, k=2)\n",
        " good = []\n",
        " for (m, n) in all_matches:\n",
        "\t        if m.distance < 0.789 * n.distance:\n",
        "\t            good.append([m]) \n",
        " if len(good) > max_val:\n",
        "  max_val = len(good)\n",
        "  max_pt = i\n",
        "  max_kp = kp2"
      ],
      "metadata": {
        "id": "t-whGeIkVl34"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if max_val != 8:\n",
        "\t    print(training_set[max_pt])\n",
        "\t    print('good matches ', max_val)\n",
        "\n",
        "\t    train_img = cv2.imread(training_set[max_pt])\n",
        "\t    img3 = cv2.drawMatchesKnn(test_img, kp1, train_img, max_kp, good, 4)\n",
        "\n",
        "\t    note = str(training_set[max_pt])[6:-4]\n",
        "\t    print('\\nDetected denomination: Rs. ', note)\n",
        "\n",
        "\t    audio_file = 'audio/' + note + '.mp3'\n",
        "else:\n",
        "  print('No Matches')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_anmziDIVpia",
        "outputId": "1f217a08-cb2c-436c-d75f-5e37bbf4db91"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/100train/INDIA100OLD_4.jpg\n",
            "good matches  2429\n",
            "\n",
            "Detected denomination: Rs.  nt/drive/MyDrive/100train/INDIA100OLD_4\n"
          ]
        }
      ]
    }
  ]
}